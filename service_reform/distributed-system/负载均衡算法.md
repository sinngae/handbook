## 负载均衡算法
web服务器集群，数据库服务器集群，分布式缓存服务集群等集群之前总有负载均衡服务。
云计算/分布式架构，本质也是把后端服务作为计算和存储资源封装到统一入口对外服务。
广泛使用的负载均衡软件：
LVS（linux virtual server)
nginx
haproxy

+ 轮询法，按顺序轮流分配到后端，均衡，不关系后端的存量连接数和系统负载
+ 随机法，按后端列表随机选取，效果接近轮询
+ 源地址哈希，同一IP客户端，总是映射到同一后端
+ 目标地址哈希？
+ 加权轮询，根据后端机器性能和负载，权重不同
+ 加权随机
+ 最小连接数，向最小连接后端分流


## 一致性哈希算法
使用Hash算法让固定的一部分请求（或者数据，下文混用）落到同一台服务器上，这样每台服务器固定处理一部分请求（并维护这些请求的信息），起到负载均衡的作用。（不论是分布式缓存还是分布式RPC服务都会使用到）。

普通的余数hash（hash(比如用户id)%服务器机器数）算法伸缩性很差，当新增或者下线服务器机器时候，用户id与服务器的映射关系会大量失效，几乎所有的数据都要移动，这个代价很大。

如何当增加或者删除节点时，大多数记录仍然分配到的原来的节点，现在仍然应该分配到那个节点，将数据迁移的代价降到最低，这就是一致性哈希要做的事情。

**环形hash空间**
把key哈希到一个大小为2^32的环形空间（头尾相连的闭合环形，由0~2^32-1的桶组成）。数据的key和存储的节点都哈希到环上，数据存放到按其key哈希值的顺时针方向找到的第一个节点上。机器的增删只需要移动迁移其顺时针方向上第一个节点上的部分数据即可。因为是把节点的信息（如ip）哈希到环上，可能会有些节点的负载很大（倾斜问题），因此引入虚拟节点，把负载分到负载小的实际节点上。

**memcached**  
memcached服务器端本身不提供分布式cache的一致性，而是由客户端来提供，具体在计算一致性hash时采用如下步骤：
+ 首先求出memcached服务器（节点）的哈希值，并将其配置到0～232的圆（continuum）上。
+ 然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。
+ 然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过232仍然找不到服务器，就会保存到第一台memcached服务器上。

**redis slot**  
Redis集群并完全实践一致性哈希，而是哈希槽（slot），Redis没有直接使用哈希算法hash()，而是使用了crc16校验算法。槽位其实就是一个个的空间的单位。其实哈希槽的本质和一致性哈希算法非常相似，不同点就是对于哈希空间的定义。一致性哈希的空间是一个圆环，节点分布是基于圆环的，无法很好的控制数据分布，可能会产生数据倾斜问题。而Redis的槽位空间是自定义分配的，类似于Windows盘分区的概念。这种分区是可以自定义大小，自定义位置的。Redis集群包含了16384个哈希槽，每个Key经过计算后会落在一个具体的槽位上，而槽位具体在哪个机器上是用户自己根据自己机器的情况配置的，机器硬盘小的可以分配少一点槽位，硬盘大的可以分配多一点。如果节点硬盘都差不多则可以平均分配。所以哈希槽这种概念很好地解决了一致性哈希的弊端。

**其他分布式哈希算法（DHT）**