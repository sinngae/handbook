lock
---

操作系统锁是为了防止多处理器并发访问临界区。
锁也造成了线程的竞争。


# 锁的底层原理
互斥锁的实现有硬件实现和软件实现。
纯软件实现锁，需要依赖一些基本的同步原语 或 假设（如原子操作 或者 对程序执行顺序的严格控制），比硬件实现需要更多的内存。而且现代计算机的流水线和乱序执行，需要手动添加 内存屏障（memory barrier）来保证 memory ordering。
一般CPU提供的构建锁的原子指令更高效，所以不讨论纯软件实现。

多核计算机，内存空间是共享的，多级缓存可能是独占的。每个核上各运行一个线程，如何保证一次只有一个线程成功抢到锁？必须要有硬件的支持。


补充说明：
这里讨论的锁都是多线程锁（同一进程的），进程间锁的实现可以基于文件锁（如实现单例运行） 或 共享内存加mutex（OS的进程通信原语） （或 锁代理？）

## 计算机的硬件支持
如果只是原子地增加变量值，使用原子操作即可，但上锁场景更加复杂。
原子操作也是通过硬件实现（总线锁定、缓存锁定），是轻量级的操作，比陷入内核要轻量很多了。

单处理器中，单条指令都可以认为是原子操作，中断只能发生在指令之间。

在SMP（Symmetric Multi-Processor，对称多处理器）体系结构中：
原子性不可能由软件单独保证--必须需要硬件的支持，因此是和架构相关的。在x86 平台上，CPU提供了在指令执行期间对总线加锁的手段。CPU芯片上有一条引线#HLOCK pin，如果汇编语言的程序中在一条指令前面加上前缀"LOCK"，经过汇编以后的机器代码就使CPU在执行这条指令的时候把#HLOCK pin的电位拉低，持续到这条指令结束时放开，从而把总线锁住，这样同一总线上别的CPU就暂时不能通过总线访问内存了，保证了这条指令在多处理器环境中的原子性。（本质上 LOCK 前缀的作用是锁定系统总线 或者 某一块cache line 来实现内存操作的原子性。加上它，就是告诉其他核，从我开始执行这个指令 到我结束LOCK 之前，谁也不许动（不许操作）。详见 缓存一致性协议 如 MESI，保证一次只有一个核对同一个内存地址赋值。）

在所有支持的体系结构上原子类型atomic_t都保存一个int值。在x86的某些处理器上，由于工作方式的原因，原子类型能够保证的可用范围只有24位。volatile是一个类型描述符，要求编译器不要对其描述的对象作优化处理，对它的读写都需要从内存中访问（而不是多级缓存，这也是锁性能不高的原因之一）。

CPU构建锁的原子（atomic）指令，如 XCHG 或 CMPXCHG（两者加上LOCK前缀）能够完成原子的 compare-and-swap(CAS)，用这样的硬件指令就可以实现spin lock。

## 操作系统的支持
基于CPU及其他硬件支持的内存操作原子性，操作系统可以通过一套简单的逻辑实现内存的锁。
多个线程持续抢占某块内存地址的值赋值1，抢到者进入临界区，没抢到继续等待（进入一个中断循环，中断、CPU切换出来、CPU调度唤醒、抢占锁。。。），抢到者临界区结束前赋值为0，等待者再次开始抢占。（这种方式构建的就是 自旋锁 spinlock，自旋的含义就是没抢到自己原地转儿。操作系统调度把线程挂起，运行其他线程，这种机制成为 互斥锁 mutex，是对spinlock的优化。是否把线程挂起，取决于是否需要等待很长时间（超时挂起？）。linux 实现的这样的一种锁称为 futex（fast UserLevel Mutex）。）

宏观来看，OS需要一些全局的数据结构记录 被挂起的线程 和 其所等待的锁的映射关系，这个数据结构天然是全局的，操作系统内核操作读写的，多个OS内核线程需要同时操作它。
所以，实现操作系统实现锁的本身也需要锁。Linux futex的巧妙之处在于，它知道访问这个数据结构不会太耗时，所以futex内部的锁就使用spinlock，而linux pthread的实现就是futex。

## 内存屏障 Memory Barrier
现代CPU为了执行效率，流水线并行、乱序执行都是基本特性，使得处理器次序和程序次序不一致，但满足 As-if-Serial特性。编译器也会优化代码执行顺序。

编译器优化乱序和CPU执行乱序可以分别用 优化屏障（Optimization Barrier）和 内存屏障（Memory Barrier）来解决。前者通过编译指令控制编译器，对于屏障后的值必须从内存中获取，不得越过屏障 乱序编译代码。

内存屏障（存储器栅栏或围栏）是一类屏障指令，可控制CPU或编译器在屏障内的操作顺序执行。
内存屏障解决的只是顺序一致性问题（sequential consistency，属于指令流水线的一部分），不解决Cache一致性问题（这是存储cache一致性协议的责任，不需程序员关注（cache coherence））。
内存屏障分为 写屏障（Store Barrier）、读屏障（Load Barrier） 和 全屏障（Full Barrier）。
屏障作用：1. 防止指令之间的重排序；2. 保证数据的可见性。

### 缓存一致性
要求：
1. 写传播 Write Propagation
高速缓存中的数据更改必须传播到对等告诉缓存中的其他副本。
2. 交易序列化 Transaction Serialization
所有处理器必须以相同顺序看到对单个存储器位置的读写。

很多CPU操作为了提升性能，大量操作异步化，如读写内存，CPU无法同步内存的改变。
Store Buffer 用于缓存写指令，直到收到其他CPU核 RFO回应后，才真正执行。
Invalidate queue用于缓存Shared->Valid状态的指令，直到CPU收到其他CPU核 RFO指令，才将对应的cache line无效化。
所以引入读写屏障。

*（unlock操作？）写屏障保证在写屏障之前的Stroe buffer中的指令都写入了缓存。*

*（lock操作？）读屏障保证在读屏障之前的所有Invalidate queue中的所有无效化指令都执行。*

有了读写屏障配合，CPU强化了缓存的控制。

锁的实现上，一般lock都加了读屏障，保证后续代码可以读到别的CPU核上的未写回的缓存数据；unlock加了写屏障，将所有的未写回的缓存进行回写。

## 原语 Primitive
原语 是操作系统或编程语言提供的基本操作或功能单元，具有下列特点：
1. 不可分割操作，也即执行过程不会被中断（原子操作），如对资源的访问
2. 系统级支持，由OS或编程语言的运行时保证，运行再内核态、保证正确性和效率。
3. 抽象性，对底层硬件或操作系统操作的抽象，隐藏复杂的细节、提供一致的简单接口。如文件操作原语（而不是磁盘字节读写）
4. 用于同步和通信，进程间同步或通信，如互斥锁、信号量、条件变量等。

### 同步原语
1. 互斥量 mutex, 一个线程独占资源
2. 信号量 Semaphore， 多个线程控制对有限资源的访问
    根据剩余资源数量控制不同线程的执行或等待。
    又称PV原语，Proberen试探 为校验；Verhogen为自增。
3. 条件变量 Condition Variable，线程间协调，满足条件则执行
    条件满足时执行，不满足则挂起。
    notify_one/notify_all，唤醒一个等待的线程（OS决定）/唤醒所有线程
4. 读写锁 RWMutex，多线程读共享、写互斥

### 通信原语
1. 管道 pipe， （父子兄弟）进程间单向流动的字节数据
2. 消息队列 Message Queue，进程间发送和接受消息
3. 共享内存 Shared Memory, 多进程共享内存，高效的数据交换
4. 信号 Signal，进程间的通知机制，互发信号

### IO原语
1. 文件操作，如open、read、write、close
2. 网络操作，如 socket、listen、connect、send、recv、close


## 锁和原子变量

Mutex的Lock 暗含Acquire语义（在此操作后的所有读写操作必须在此操作之后，但不保证此操作前的操作是否发生在此操作后）；Unlock暗含Release语义（在此操作前的所有读写操作必须发生在此操作前，但不保证此操作后的读写操作是否发生在此操作前）。
由此，Mutex不仅会保证执行的序列化，同时也保证访问的一致性。
类似的，OS提供的原子变量除了保证内存操作原子之外，也保证访问的一致性。
GCC提供了Built-in原子操作函数，GCC 4以后的版本提供了Built-in屏障函数 `__sync_synchronize()`，这个即是编译屏障也是内存屏障。

无锁的代码仅仅是不需要显式的Mutex来完成，只要存在数据竞争（Data Races）就会涉及同步问题。换个角度看，所谓的无锁，只是颗粒度特别小的锁罢了，从代码层面逐渐控制级别到CPU的指令级别而已，总会在某个层级上付出等待的代价，除非逻辑上不构成数据竞争。（无锁编程对应Lockfree编程 和 Lockless编程，是两个完全不同的概念，是编程模式 前者实现难度太高。无锁队列这种可证明正确性的使用场景受限 但具体情况也可用。而CAS这种乐观锁在多核情况不见得高效，竞争厉害的时候总体消耗可能更高。）



# 自旋锁
+ spinlock 自旋锁
    + 获取不到锁，则自旋等待，忙等，不会睡眠
    + 不可抢占，可被中断
    + 一直处于用户态，不会做系统调用（不会陷入内核）
    + 缺点：一直占用cpu，而且持有锁既锁bus总线，其他处理器不能使用bus总线。
+ mutex 互斥锁
    + 获取不到锁，则sleep，挂起当前线程
    + mutex获取锁分为两阶段
        + 第一阶段在用户态采用spinlock锁总线的方式获取一次锁，如果成功立即返回；
        + 否则进入第二阶段，调用系统的futex锁去sleep，当锁可用后被唤醒，继续竞争锁。
    + 缺点：mutex 会陷入内核，进入昂贵的系统调用
+ futex - fast mutex
+ semaphore 信号量
    + 控制并发度
    + 获取不到锁，则等待？
+ 读写锁
    + 作用：区分读写操作，支持读操作的并发、写操作的互斥
    + 工作模式 Go Write-Prefer
        + Read-preferring 优先读，可能导致写饥饿
        + Write-preferring 优先写，避免写饥饿
        + 不指定优先，无饥饿问题
    + 实现
        + 使用互斥锁和信号量实现

试用场景
+ spinlock 适用锁持有时间较短的场景，睡眠是不必要的，自旋锁效率远高于互斥锁。
+ semaphore 适用锁持有时间较长的场景，

faq
+ AA锁问题 重复加锁导致的死锁
    + 需要支持recursive 递归锁即可解决
+ AB-BA锁问题 互相持有导致的互相等待的死锁
    + 需要设计锁的添加顺序
    + 一般操作系统都有死锁检测
+ 获得锁之后，线程崩溃了，锁会释放掉么
    + 会造成未定义的行为
+ spinlock 基于硬件的CAS（compare and swap）?
    + rwlock是基于spinlock实现的
    + mutex的实现也依赖spinlock

## spinlock的多种实现方式
1. CAS compare and swap

最古老的一种做法是：spinlock用一个整形变量表示，其初始值为1，表示available的状态。当一个CPU（设为CPU A）获得spinlock后，会将该变量的值设为0，之后其他CPU试图获取这个spinlock时，会一直做CAS，直到CPU A释放spinlock，并将该变量的值设为1。

那么其他的CPU是以何种形式等待的，如果有多个CPU一起等待，形成了竞争又该如何处理？这里要用到经典的CAS操作（Compare And Swap）。

CAS 很快，但是缺点：它是「不公平」的。 一旦spinlock被释放，第一个能够成功执行CAS操作的CPU将成为新的owner，没有办法确保在该spinlock上等待时间最长的那个CPU优先获得锁，这将带来延迟不能确定的问题。


2. Ticket Spinlock
采用排队形式的"ticket spinlock"。如 x86-64 ACRN版本、Linux实现。

使用ticket spinlock可以让CPU按照到达的先后顺序，去获取spinlock的所有权，形成了「有序竞争」。根据硬件维护的cache一致性协议，如果spinlock的值没有更改，那么在busy wait时，试图获取spinlock的CPU，只需要不断地读取自己包含这个spinlock变量的cache line上的值就可以了，不需要从spinlock变量所在的内存位置读取。

但是，当spinlock的值被更改时，所有试图获取spinlock的CPU对应的cache line都会被invalidate，因为这些CPU会不停地读取这个spinlock的值，所以"invalidate"状态意味着此时，它们必须重新从内存读取新的spinlock的值到自己的cache line中。

而事实上，其中只会有一个CPU，也就是队列中最先达到的那个CPU，接下来可以获得spinlock，也只有它的cache line被invalidate才是有意义的，对于其他的CPU来说，这就是做无用功。内存比cache慢那么多，开销可不小。

# 乐观锁 & 悲观锁
乐观锁和悲观锁是业务逻辑实现并发的概念，不应该和数据锁混淆。
随着高并发、高可用、高性能的架构诉求，越来越少使用悲观锁在生产环境中。

乐观锁
+ 对数据冲突持乐观态度，不对需要操作的数据加锁
+ 通过业务逻辑实现锁的等价功能
    + 业务逻辑CAS（compare and set），业务重试
    + 版本号控制，对版本号做CAS
    + 使用分布式事务锁？比如ZK、redis
+ 适用于冲突少的(写少读多)、高并发场景
+ 冲突多的时候反而浪费更多资源

悲观锁
+ 对数据冲突持悲观态度，对需要操作的数据先锁定
+ 一般通过数据库锁机制，将数据锁定
+ 共享锁 VS 排他锁
    + 共享锁，读锁、S锁，多个事务只能读，不能修改
    + 排他锁，写锁、X锁，不能与其他锁并存
+ 适用于冲突多（读少写多）
+ 锁限制了并发，还可能产生死锁


# 无锁队列 Lock-free Queue
