# 数据结构专题
数据结构是计算机技术的基石之一，与算法密切相关。

数据结构不是纸面上的模型，而是与计算机密不可分的。比如，程序运行期间内存数据结构(stl库的各种容器)、存储设备上的文件存储结构、数据库服务的数据结构、网络传输的数据结构等等。

## 分类
- 序列式容器
vector list queue
- 关联式容器
set map multiset multimap
- 配置式容器
queue stack priority_queue
- 无序管理式容器

## 树
+ 每个节点都只有有限个子节点或无子节点；
+ 没有父节点的节点称为根节点；
+ 每一个非根节点有且只有一个父节点；
+ 除了根节点外，每个子节点可以分为多个不相交的子树；
+ 树里面没有环路(cycle)

节点的度：一个节点含有的子树的个数称为该节点的度；  
梅开几度,花香几处？梅开二度？

+ 无序树：  
树中任意节点的子节点之间没有顺序关系，这种树称为无序树，也称为自由树；
+ 有序树：  
树中任意节点的子节点之间有顺序关系，这种树称为有序树；
    + 二叉树：  
每个节点最多含有两个子树的树称为二叉树；
        + 完全二叉树：  
对于一颗二叉树，假设其深度为d（d>1）。除了第d层外，其它各层的节点数目均已达最大值，且第d层所有节点从左向右连续地紧密排列，这样的二叉树被称为完全二叉树；
            + 满二叉树：
            + 堆  
所有叶节点都在最底层的完全二叉树；
        + 平衡二叉树（AVL树是一种平衡二叉树，还有其他类型？）：  
当且仅当任何节点的两棵子树的高度差不大于1的二叉树；
排序二叉树（二叉查找树（英语：Binary Search Tree））：
也称二叉搜索树、有序二叉树；
    + 霍夫曼树：  
带权路径最短的二叉树称为哈夫曼树或最优二叉树；
    + B树：  
一种对读写操作进行优化的自平衡的二叉查找树（一般是两个及两个以上叉），能够保持数据有序，拥有多于两个子树。

树的度：一棵树中，最大的节点度称为树的度；

平衡搜索树的实现：AVL树（高度平衡树）Splay树(伸展树) 红黑树 费波拉齐亚树 B树  
每种树都有各自的使用场景，并无对错之分，却有效率之取舍

## 堆
堆为二叉树的一种；由于其应用的普遍性，当不加限定时，均指该数据结构的这种实现。

这种数据结构具有以下性质：
+ 任意节点小于（或大于）它的所有后裔，最小元（或最大元）在堆的根上（堆序性）。  
+ 堆总是一棵完全二叉树。

即除了最底层，其他层的节点都被元素填满，且最底层尽可能地从左到右填入。
+ 局部有序：每条路径上是有序的
+ 插入、删除的时候，可能需要更多操作（相比于左序、右序、中序等二叉树）
+ 使用数组实现即可？较好的空间利用

将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。  
常见的堆有二叉堆、斐波那契堆等。  
常用于排序、选择优先级，是戴克斯特拉算法(Dijkstra's algorithm)的关键

场景
+ 堆排序
+ 优先级队列
+ 求Top n
+ 求中位数，使用一个大顶堆和一个小顶堆实现

## 二叉树
每个节点最多只有两个分支（即不存在分支度大于2的节点）的树结构
### 二叉搜索树
+ 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值；
+ 若任意节点的右子树不空，则右子树上所有节点的值均大于或等于它的根节点的值；
+ 任意节点的左、右子树也分别为二叉查找树；

二叉搜索树最坏O(n)，AVL树和红黑树可以达到O(log n)

### 自平衡二叉查找树
改进的二叉查找树，自平衡二叉查找树  
一般二叉查招树的查询复杂度取决于目标节点到根节点的深度，因此，深度较大时，某些节点的操作耗时会上升。而平衡树通过算法使所有分支的深度趋于平衡，均摊了耗时。  
因算法不同，平衡树分为：AVL树/树堆(Treap)/伸展树/红黑树/加权平衡树/2-3树/AA树/替罪羊树

### 二叉树的遍历
遍历二叉树：L、D、R分别表示遍历左子树、访问根结点、遍历右子树
+ 深度遍历
    + 前序遍历（先根遍历） D=>Left=>Right
    + 中(根)序遍历 Left=>D=>Right
    + 后(根)序遍历 Left=>Right=>D
+ 广度遍历
    + 按层遍历
        + 广度优先，需要借助队列实现

这些方法的时间复杂度都是O(n)，n为结点个数。

## B树
B树，名字无明确单词（大多数认为是balance tree，但是也不要翻译成自平衡树/平衡树/多叉平衡树，B树就是B树），一种保持数据有序的树。  
数据的查找、顺序访问、插入、删除都在对数时间内完成。  
目前大部分数据库系统及文件系统都采用B-Tree或其变种B+Tree作为索引结构。

定义  
根据 Knuth 的定义，一个 m 阶的B树是一个有以下属性的树：
每一个节点最多有 m 个子节点  
每一个非叶子节点（除根节点）最少有 ⌈m/2⌉ 个子节点  
如果根节点不是叶子节点，那么它至少有两个子节点  
有 k 个子节点的非叶子节点拥有 k − 1 个键  
所有的叶子节点都在同一层  

每一个内部节点的键将节点的子树分开。  

算法

性能  
定位百万笔记录中的一个记录，需要将近20个比较级完成。

理念  
保持键值有序，以顺序遍历  
使用层次化的索引来最小化磁盘读取  
使用不完全填充的块来加速插入和删除  
通过优雅的遍历算法来保持索引平衡  
另外，B树通过保证内部节点至少半满来最小化空间浪费。一棵B树可以处理任意数目的插入和删除。

弊端  
除非完全重建数据库，否则无法改变键值的最大长度。这使得许多数据库系统将人名截断到70字符之内

### B+树
B树变种  
B+ 树是一种树数据结构，通常用于数据库和操作系统的文件系统中。  

B+Tree相对于B-Tree有几点不同：
+ 非叶子节点只存储键值信息
+ 所有叶子节点之间都有一个链指针
+ 数据记录都存放在叶子节点中

在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度。

通过最大化在每个内部节点内的子节点的数目减少树的高度，平衡操作不经常发生，而且效率增加了。这种价值得以确立通常需要每个节点在次级存储中占据完整的磁盘块或近似的大小。

B+ 树的特点是比一般B树数据操作更稳定，其插入与修改拥有较稳定的对数时间复杂度。  


算法  
+ 查找  
查找以典型的方式进行，类似于二叉查找树。起始于根节点，自顶向下遍历树，选择其分离值在要查找值的任意一边的子指针。在节点内部典型的使用是二分查找来确定这个位置。

+ 插入  
节点要处于违规状态，它必须包含在可接受范围之外数目的元素。  
首先，查找要插入其中的节点的位置。接着把值插入这个节点中。  
如果没有节点处于违规状态则处理结束。  
如果某个节点有过多元素，则把它分裂为两个节点，每个都有最小数目的元素。在树上递归向上继续这个处理直到到达根节点，如果根节点被分裂，则创建一个新根节点。为了使它工作，元素的最小和最大数目典型的必须选择为使最小数不小于最大数的一半。
+ 删除  
首先，查找要删除的值。接着从包含它的节点中删除这个值。  
如果没有节点处于违规状态则处理结束。  
如果节点处于违规状态则有两种可能情况：  
它的兄弟节点，就是同一个父节点的子节点，可以把一个或多个它的子节点转移到当前节点，而把它返回为合法状态。如果是这样，在更改父节点和两个兄弟节点的分离值之后处理结束。  
它的兄弟节点由于处在低边界上而没有额外的子节点。在这种情况下把两个兄弟节点合并到一个单一的节点中，而且我们递归到父节点上，因为它被删除了一个子节点。持续这个处理直到当前节点是合法状态或者到达根节点，在其上根节点的子节点被合并而且合并后的节点成为新的根节点。

mysql存储引擎InnoDB采用索引类型B+树  
数据库索引采用B+树的主要原因是：B树在提高了IO性能的同时并没有解决元素遍历的效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作（或者说效率太低）。

数据库中的B+Tree索引可以分为聚集索引（clustered index）和辅助索引（secondary index）。聚集索引的B+Tree中的叶子节点存放的是整张表的行记录数据。

辅助索引与聚集索引的区别在于：  
辅助索引的叶子节点并不包含行记录的全部数据，而是存储相应行数据的聚集索引键，即主键。

当通过辅助索引来查询数据时，InnoDB存储引擎会遍历辅助索引找到主键，然后再通过主键在聚集索引中找到完整的行记录数据。

### 2-3树
内存中的查找表场景中  
B树却不一定比平衡二叉树好，尤其当m较大时更是如此。m较大时,B树的查找复杂度O(m log-t n)比平衡二叉树的操作时间大得多。因此在内存中使用B树必须取较小的m。通常取最小值m=3，此时B-树中每个内部结点可以有2或3个孩子，这种3阶的B-树称为2-3树。


## AVL树
由发明人命名，Adelson-Velsky and Landis Tree  
是一种自平衡二叉查找树，其任一节点对应的两棵子树的最大高度差为1，因此它也被称为高度平衡树。查找、插入和删除在平均和最坏情况下的时间复杂度都是O(log n)。

节点的平衡因子是它的左子树的高度减去它的右子树的高度（有时相反）。带有平衡因子1、0或 -1的节点被认为是平衡的。带有平衡因子 -2或2的节点被认为是不平衡的，并需要重新平衡这个树。平衡因子可以直接存储在每个节点中，或从可能存储在节点中的子树高度计算出来。

算法

因插入或删除失去平衡的AVL树的四种情况及处理：  
某节点的两个子节点位于其的左左/右右/左右/右左（后两者先右旋/左旋成左左/右右。都需要抬中（把中间节点旋转为中心节点）。）

## 红黑树
1972年由鲁道夫·贝尔发明，被称为"对称二叉B树"，RBT(Red-Black Tree)  
是一种自平衡二叉查找树  
红黑树可以在O(log n)时间内完成查找，插入和删除。

红黑树相对于AVL树来说，牺牲了部分平衡性（通过对任一条从根到叶子的路径上各个节点着色的方式的限制，红黑树确保没有一条路径会比其它路径长出两倍）以换取插入/删除操作时少量的旋转操作。

一种弱平衡二叉树(相同的节点情况下，AVL树的高度低于红黑树)，相对AVL树，它的旋转次数变少，所以对于搜索、插入、删除操作多的情况下，就用红黑树。


约束  
在二叉查找树强制一般要求以外，对于任何有效的红黑树要求：
+ 节点是红色或黑色  
+ 根是黑色  
+ 所有叶子都是黑色（叶子指NIL/NULL节点）  
+ 如果一个节点是红色，其两个子节点必须都是黑色  
从每个叶子到根的所有路径上不能有两个连续的红色节点
+ 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点

算法

应用  
+ 广泛用于C++的STL中，map和set都是用红黑树实现的。  
+ 著名的linux进程调度Completely Fair Scheduler，使用红黑树管理进程控制块，进程的虚拟内存区域都存储在一颗红黑树上，每个虚拟地址区域都对应红黑树的一个节点，左指针指向相邻的地址虚拟存储区域,右指针指向相邻的高地址虚拟地址空间。
+ IO多路复用epoll的实现采用红黑树组织管理sockfd，以支持快速的增删改查。
+ ngnix中，用红黑树管理timer，因为红黑树是有序的，可以很快的得到距离当前最小的定时器。

## 双向链表

## 跳跃表
跳跃列表由威廉·普发明。发明者对跳跃列表的评价是：“跳跃列表是在很多应用中有可能替代平衡树而作为实现方法的一种数据结构。跳跃列表的算法有同平衡树一样的渐进的预期时间边界，并且更简单、更快速和使用更少的空间。”

跳跃列表的最坏时间性能具有一定随机性，但是可以通过时间复杂度为O(n)的遍历操作（例如在打印列表全部内容时）以无随机的算法重整列表的结构，从而使跳跃列表的实际查找时间复杂度尽量符合理论平均值O(log n)。

## hashtable
散列表/哈希表，根据键（Key）和映射函数而直接访问在内存储存位置的数据结构。  
该映射函数称为散列函数，存放的数组称为散列表。
牺牲空间，来做到高效的查找。

数据结构  
链表数组，数组以hashcode为元素，元素指向一个链表，碰撞的key放在同一链表。
计算一个因子，如果因子数较大则调整链表数组，使数组增长。

散列函数  
+ 除留余数法
+ 伪随机数法 (平方取中法)
弱点很大

HashTable是根据Hash的特点去解决这种问题：海量数据的索引、插入、删除时，可以先hash一下，将海量数据进行分块，然后再进行搜索、插入、删除等操作，以便降低时间复杂度。在最好的情况下，能够将时间复杂度降低到O(1)。

    据《算法导论》上讲：“很多应用中，都需要一种动态的集合结构，它仅仅支持INSERT、SEARCH和DELETE字典操作...实现字典操作的一种有效的数据结构为散列表（Hash Table）...在散列表中，查找一个元素的时间与在链表中查找一个元素的时间相同，最坏情况下都是O(n)...散列表是普通数组概念的推广...”。也就是说，Hash Table是为了解决动态的插入、搜索、删除等操作，而专门设置的一种数据结构，目的为了降低这些操作的时间复杂度。

这里面有个“字典操作”，“字典”模型是这样的：通过某个关键字，能够查到该关键字相关的信息，比如通过身份证号，可以查到姓名、性别、年龄、婚否等信息。这样，就抽象出两个关键的部分key和value，身份证号码——key，姓名、性别、年龄、婚否——value。

**java的hashmap与hashtable的区别**  
链表数组 和 红黑树？


## 交叉问题

### 1.树和堆的区别
堆是一种完全二叉树，除了最外一层，每一层的节点都达到最大值，最后一层的节点从左到右填充。
堆常用于优先队列、堆排序，支持快速插入和删除最大或最小值。

## 2.堆排序


## hashtable 和 swissTable

### 理想的hash函数
1. 相同的key计算的hash值总是相同的；不同的key计算的结果也完全不同；
    通常比较难以遇到不同数据产生相同的hash值，近似成立
2. hash值得每一个bit都是随机的，且随机概率均等；

hash函数完美，但是key映射到有限大小的内存空间，不可避免会产生冲突，两个key被映射到同一个位置。

### 两种解决冲突的方法

有限大小的存储空间，n个位置，每个位置为一个slot，用于存放value。

1. 链表法
插入时，映射到相同位置的key和value存储到一张链表里，头部插入。
删除时，同链表删除。
查询时，先映射到位置，再遍历链表。

实现简单，长链表可转为搜索树。
链表对缓存不友好（在内存空间随机、不连续），冲突多的时缓存命中率降低从而影响性能。
（为什么不用vector，新增、删除元素需要移动大量元素，性能和稳定性都没有保证 不实用）

2. 线性探测法

插入时，从冲突的位置开始向后查找空位（可以是删除的），如果没有则扩容整个存储空间。
删除时，标记为删除的，而不是空的。
查询时，从冲突位置向后查找，遇到删除的则跳过，直到遇到相同的key 或 空的slot（key不存在）。


缓存友好，slot利用率高。
实现复杂，一处冲突影响多个slot 进而连锁式冲突 进而扩容次数更多 进而用掉更多内存。
查找退化到O(n)。
没有指针稳定性（）。


### swissTable
swissTable 时间复杂度和线性探测法差不多，空间复杂度在链表法 和 线性探测之间。
核心思想，将查询等需要的元数据（slot状态，是否能存数据、是否存了数据、是否元素被删）提取出来，用于操作优化，提升内存效率和CPU效率（相比直接用slot数据计算更优）。

具体的，可见abseil库实现的。
1. hash函数计算结果 64bit，57bit的H1用于确定slot位置；7bit的H2用作当前key的特征值，用于查询。
2. 和slot一一对应的control bytes，存放元数据（slot是否为空、是否删除、hash特征值H2、是否边界），尾部存放一个边界值。
3. 查询或插入、删除等操作都需要找到key映射的位置，利用现代CPU的SIMD指令可一次性比较128bit，先计算出特征值相等的，再访问slot对比key相等的。这样整体便利快很多，hash表的吞吐量有质的飞跃。
    如果CPU不支持，可以用位运算实现，效果和不用swisstable差不多，现代CPU大多支持。

需要 hash函数足够完美，H2特征值的每个bit概率均等。

rust已经采纳swisstable作为map的实现，golang也会。

