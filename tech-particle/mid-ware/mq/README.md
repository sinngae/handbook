Message Queue 消息队列
---
> 必知必会，Kafka RocketMQ
>> 可选，rabbitMQ、nsq


# 消息队列
削峰限流


## Kafka
+ 消息分类，Topic
+ 分区，分成多个partition
+ 分布式多机器部署，每个机器上一个broker
+ 副本，节点异常集群可用
+ 持久化，异常重启可用
+ 保留策略，超过一定大小或时间就清理掉
+ 消费者组，同一个消费者组并发消费
+ ZK，一致性保证；后续改成Raft

底层分为多个segment文件，每个文件是顺序写，但是多个文件整体是随机写。

## RocketMQ
国产自研，参考了Kafka，架构上做减法，功能上做加法
+ 简化协调，去掉ZK，使用nameserver
+ 分区，成为queue；commitlog 只有一个文件，（多个topic）全局顺序写
+ 先读queue，再读commitlog；commitlog在不同的broker区分主从
+ 支持按tag标记分类，在服务端分类
+ 事务支持？
+ 延时队列，指定时间
+ 死信队列，失败的消息重试
+ 调整offset 或 时间 来消费


## Kafka 和 RocketMQ的主要差异
两者都可以批处理、数据压缩。

Kafka基于sendfile处理文件读写，而RocketMQ基于mmap。

一般地，OS接口的文件读写 read() write()各需要两次内存拷贝（内核的文件缓冲区），需要四次内核态和用户态的相互切换，成本极高。

Kafka操作系统的sendfile 使用DMA 硬件控制，实现零CPU拷贝（实际还是有两次拷贝操作的）。
RocketMQ使用mmap映射，省却一次（读取到内核的文件缓冲直接映射到用户态的内存空间）但效果不多。

### 为什么rocketmq 不用sendfile

+ sendfile CPU不参与，不可读取发送的数据，只知道发送的字节数；mmap返回的是具体的数据
+ RocketMQ需要具体的数据，判断是否失败重新投递
+ Kafka追求极致性能

是性能和功能的折中。

### RocketMQ有的功能而Kafka没有的

+ 消息顺序性，严格的消息顺序（即使一台broker宕机，也能确保消息的顺序场景），适用金融交易、订单处理等，保障业务的正确性和一致性
+ 消息过滤，前者可以根据消息标签过滤，还提供了数据格式转换（Kafka 需要借助Kafka Streams 等工具实现、较为复杂）
+ 事务消息，采用两阶段提交协议，确保消息的原子性操作，适用订单支付、库存扣减等业务场景（kafka 对应的Exactly Once 实现和配置较为复杂）
+ 延迟队列，可设定时间延迟投递消息，适用定时任务、延迟通道
+ 高队列数支持，单机支持最高5w个队列，适用大规模分布式系统（Kafka单机超过64个队列时，性能开始显著下降，底层文件变成大量分区，吞吐量受影响）
+ 消息追踪，消息的发送、存储、消费可追踪，便于排查问题和监控消息的流转

Kafka 拥有丰富的生态系统和社区支持，与大数据处理框架（Spark\Flink）集成良好，方便做实时数据分析和流式处理。
Kafka支持故障转移和数据复制机制，能够快速恢复节点。

### RocketMQ两阶段提交协议

### RocketMQ的拉取策略
基于拉取模式（Pull Model），也即长轮询机制来实现高效的消息消费。
+ 消费者发送拉取请求，指定消息队列和偏移量
+ Broker收到请求，从队列读取消息并返回。如果没有消息，则等待一段时间
+ 消费者处理消息(提交偏移量)，然后继续拉取

即时性，有新消息几乎实时获取；不会频繁无结果轮询；消费者控制节奏，不会压力过大；

kafka也支持长轮询机制，但默认行为是更频繁的拉取，适用于高吞吐场景；


###  exactly once semantics(EOS 恰好一次)
Kafka 生产者幂等性 + 事务机制来实现
+ 生产者开启幂等性，保证不会重复投递
+ 在事务中发送消息，发送消息视为原子操作，并可提交或回滚
+ 消费者隔离级别设置为read_committed，只消费已提交的消息

rocketMQ 
+ 生产者通过消息唯一ID设置避免重复发送
+ 消费者通过记录消息唯一ID避免重复消费
+ 通过两阶段提交协议来保证消息发送和本地事务操作的原子性

看起来是配置参数不同，机制是一样的。

## 场景不同
+ 大数据场景，Kafka 结合 Spark Flink 处理数据流，事件流
+ 日志流、监控数据流等
+ 其他尽量使用RocketMQ，如业务数据


