分布式理论专题
---

# CAP理论
> 维基百科：

> In theoretical computer science, the CAP theorem, also named Brewer’s theorem after computer scientist Eric Brewer, states that any distributed data store can only provide two of the following three guarantees:

> Consistency : Every read receives the most recent write or an error

> Availability : Every request receives a (non-error) response – without the guarantee that it contains the most recent write

> Partition tolerance : The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes

任何**分布式存储系统**只能保证CAP中的两个：
+ Consistency 一致性  
    + 分布式集群中，对同一数据的多个备份的访问是一致的，要么失败
        + 集群对客户端承诺：绝对最新的数据，要么就失败
    + 对客户请求，每次读取的数据要么是最新的数据，要么读取失败
+ Availability 可用性  
    + 分布式集群对客户端承诺：一定返回数据，但不一定是最新的
    + 任何请求都能得到正确的响应，不完全保证获取的数据为最新
+ Partition tolerance 分区容错性 
    + 分布式系统内部同通过不可靠的网络通讯
        + 部分节点不可用，整个系统仍然提供服务
        + 分布式集群中，一部分节点故障，整体仍然可用

当集群内网络访问失败时，有两个选择：
1. 取消当前操作，可用性降低 但确保了一致性。
2. 继续当前操作，可用性高 但没法保证一致性。


+ CA =》 单体应用
    + 节点（单体）不可用，则服务不可用
    + 或者网络失败不存在的情况下（分布式服务正常运行）
+ CP =》 
    + 网络分区后，不能保证取到的数据是最新的，则报错；服务可用
+ PA => 
    + 网络分区后，无法保证获取最新的数据，但保证请求到数据
    + 如果要获取最新的数据（即达到一致性），则需要阻塞请求，等待数据同步。进而服务不可用？

CAP理论是分布式系统下网络故障的风险的容忍问题。

CAP的误导：并不总是三者取二，在很多系统中是不用分区的，只是单体？

实际效果，跨区跨机房的服务通信失败很正常（丢包、延时），如果不能在有限时间内完成通信，则发生异常，分区不可用。所以，分布式设计中一定会考虑分区容错。
CAP三者不可得兼，舍一存二（CP/PA）。
经典关系数据库的事务一致性、读写实时性、多表关联查询等很多特性在Web2.0被选择性抛弃了。

**CAP和NoSQL**  
NoSQL更注重性能和可扩展性，而非事务机制（经典关系数据库支持ACID强事务性）。
NoSQL仅提供行级别的原子性保证，即对同一`key-value`操作两次，是串行处理，保证ACID。

**Base理论**  
1. 基本可用 Basically Available
允许部分不可用，整体或核心可用
2. 软状态 Soft State
允许不同节点间副本间同步延时，不影响整体可用。
3. 最终一致性 Eventually Consistency
所有副本最终一致。

Base的思想是即使做不到强一致性，也要达到最终一致性。
这样，分布式的多个副本可以异步复制，达到高性能和最终一致。
最终一致性需要保障用户感知的一致性，用户的不一致窗口取决于通信延时/系统负载/副本复制个数。

DNS是典型的最终一致性。

*acid为酸，base为碱

## 
https://codahale.com/you-cant-sacrifice-partition-tolerance/



# 共识算法
## Paxos算法
paxos算法是LaTex开发者计算机科学家 莱斯利 兰伯特 提出的，一种基于消息传递且具有高度容错特性的共识（consensus）算法（共识算法不是为了达到一致性，而是分区高度容错的消息传递机制）。

+ 首先将议员的角色分为 proposers，acceptors，和 learners（允许身兼数职）。
+ proposers 提出提案，提案信息包括提案编号和提议的 value；
+ acceptor 收到提案后可以接受（accept）提案，若提案获得多数派（majority）的 acceptors 的接受，则称该提案被批准（chosen）；
+ learners 只能“学习”被批准的提案。

划分角色后，就可以更精确的定义问题：
+ 决议（value）只有在被 proposers 提出后才能被批准（未经批准的决议称为“提案（proposal）”）；
+ 在一次 Paxos 算法的执行实例中，只批准（chosen）一个 value；
+ learners 只能获得被批准（chosen）的 value。

**quorum机制？**

*zk集群的zab协议基于paxos，但并没有完全实现。

## Raft算法
raft算法是要提供更好理解的共识算法，并提供与paxos相同的容错和性能。

Raft透过选举领袖（leader）的方式实做共识算法。

在Raft集群（Raft cluster）里，服务器可能会是这三种身份其中一个：领袖（leader）、追随者（follower），或是候选人（candidate）。在正常情况下只会有一个领袖，其他都是追随者。而领袖会负责所有外部的请求，如果不是领袖的机器收到时，请求会被导到领袖。

通常领袖会借由固定时间发送消息，也就是“心跳（英语：heartbeat）”，让追随者知道集群的领袖还在运作。而每个追随者都会设计超时机制（timeout），当超过一定时间没有收到心跳（通常是150 ms或300 ms），集群就会进入选举状态。

Raft将问题拆成数个子问题分开解决，让人更容易了解：
+ 领袖选举（Leader Election）
+ 记录复写（Log Replication）
+ 安全性（Safety）

最大容错(n-1)/2，超出后集群不可用。

## pbft算法（联盟链）
**拜占庭将军问题**
raft算法的的容错只支持容错故障节点，不支持容错作恶节点。
拜占庭将军里，存在间谍将军。

## 公链共识算法
pbft算法用于联盟链；Raft算法用于私链；还有公链算法

# 分布式管理
## zookeeper

## etcd
